# -*- coding: utf-8 -*-
"""ML-Model_Tournament_Telco.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WzgW091LB4CKQSxAH4f8hZTVu9VLUM1C

# SUP ML 2 - MODEL
"""



"""# Libraries"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

pd.set_option('display.max_columns',None)

import warnings
warnings.filterwarnings("ignore")

"""# Carga clean data"""

from google.colab import drive
drive.mount('/content/drive')

df=pd.read_pickle("/content/drive/MyDrive/DSC 0523– Entregable 2 - Borrero, Dottori, He/Modelo/EJERCICIO-ML-Sup/data/ df_limpio_completo_Preprocessing_Final_ML_PK")

df.shape

from sklearn.feature_selection import VarianceThreshold
vt = VarianceThreshold(threshold = 0.01)
vt.fit(df)
cols_lowvar = df.columns[vt.get_support()==False]
df.drop(columns=cols_lowvar,inplace=True)
print(len(cols_lowvar),' low variance features were removed:\n', cols_lowvar.to_list())

correlation_matrix = df.corr()

mean_correlation = correlation_matrix.mean().sort_values(ascending=False)

print("Correlación media con todas las demás variables:")
with pd.option_context('display.max_rows', None, 'display.max_columns', None):
    print(mean_correlation)

df.shape

"""# Distribución del target"""

df['churn'].value_counts()

df.hist('churn')

proportion_churn = (df['churn'].value_counts()) / (len(df['churn'])) *100
proportion_churn

print(f'La distribucion de clientes que abandonan o permanecen en el servicio es proporcional')
print(f'{proportion_churn}')

target = 'churn'
features = df.columns[df.columns!=target]

X=df[features]
y=df[target]

sns.distplot(y)
plt.title('Distribucion del target: '+target)
plt.show()

"""# Undersampling (*)

**NOTA:** SOLO EN CLASIFICACIÓN cuando el ratio de éxitos está MUY DESBALANCEADO (<10%).
"""

target = 'churn'
features = df.columns[df.columns != target]

y = df[target]
X = df[features]

pd.Series(y).value_counts() / len(y)

sns.countplot(x=y)
plt.title(target+' distribution')
plt.show()

"""# Split TRAIN-TEST"""

df.reset_index(drop=True,inplace=True)

from sklearn.model_selection import train_test_split, cross_val_score

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)

print('--- TRAIN ---')
print('Size: {:,}'.format(len(y_train)))
print('Positive cases: {:,}'.format(sum(y_train)))
print('Positive rate: {:.2%}'.format(sum(y_train)/len(y_train)))
print('\n--- TEST ---')
print('Size: {:,}'.format(len(y_test)))
print('Positive cases: {:,}'.format(sum(y_test)))
print('Positive rate: {:.2%}'.format(sum(y_test)/len(y_test)))

print('Train set size:',X_train.shape[0])
print('Test set size:',X_test.shape[0])

"""# Rescaling

* NO NECESARIO en modelos de Arboles de Decisión.
* Guardar scaler en el model path.
"""

# NO HACE FALTA

"""# TRAIN-VALIDA

## Torneo de Modelos

* Probamos una colección de modelos con el objetivo de conseguir el mejor rendimiento del modelo en los datos de VALIDACION.
"""

from sklearn.metrics import roc_auc_score, f1_score

from sklearn.model_selection import cross_val_score
from sklearn.metrics import roc_auc_score
from sklearn.linear_model import LogisticRegression, Ridge, Lasso, ElasticNet, SGDRegressor
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier

def auc(model,X,y):
  model.fit(X,y)
  return roc_auc_score(y,model.predict_proba(X)[:,1])

def auc_cross_validation(model,X,y):
  cross_val = cross_val_score(model,
                              X, y,
                              cv=4,
                              scoring='roc_auc'
                              )
  return cross_val.mean()

label_, auc_train_ , auc_valida_ = [], [], []

def evaluate_classification(model, X, y, label=None):
  if label is None:
    label=str(model)
  label_.append(label)
  auc_train = auc(model,X,y)
  auc_valida = auc_cross_validation(model,X,y)
  auc_train_.append(auc_train)
  auc_valida_.append(auc_valida)
  return pd.DataFrame({'Model': label_,
                      'AUC Train': auc_train_,
                      'AUC Cross-Valida': auc_valida_
                      }).sort_values('AUC Cross-Valida',ascending=False)

evaluate_classification (model = RandomForestClassifier(n_estimators=100, max_depth=3),
                    X=X_train, y=y_train)

evaluate_classification (model = KNeighborsClassifier(n_neighbors = 10),
                    X=X_train, y=y_train)

evaluate_classification(model = XGBClassifier(n_estimators=100, max_depth=3),
                    X=X_train, y=y_train)

evaluate_classification(model = LogisticRegression(),
                    X=X_train, y=y_train)

evaluate_classification(model = GradientBoostingClassifier(n_estimators=100, max_depth=3),
                    X=X_train, y=y_train)

"""## Hiperparametrizacion

* Utilizar RandomSearch para probar diferentes configuraciones de los parametros del modelo ganador en el torneo de modelos con el objetivo de mejorar el control del overfitting.
"""

from sklearn.model_selection import RandomizedSearchCV

XGBClassifier()

parametros = {
    'max_depth': [3, 6, 9],
    'n_estimators': [100,200,400],
    'min_child_weight': [1,2,3],
    'subsample' : [0.8],
    'alpha' : [0.5],
}

random_search = RandomizedSearchCV(estimator = XGBClassifier(),
                  param_distributions = parametros,
                   n_iter = 20,
                   scoring = 'roc_auc',
                   cv = 4,
                   )

random_search.fit(X_train, y_train)

print("---- Results from Random Search -----" )
print("\n The best estimator across ALL searched params:", random_search.best_estimator_)
print("\n The best AUC:", random_search.best_score_)
print("\n The best parameters across ALL searched params:\n", random_search.best_params_)

"""## Modelo final

* Entrenar el modelo final con el algoritmo y los parametros que hanfuncionado mejor en anteriores experimentos.
* Argumentar la elección.
* Guardar el modelo en model path.
"""

model = random_search.best_estimator_

print('AUC Train:', auc(model, X_train, y_train))

print('AUC CV:', auc_cross_validation(model, X_train, y_train))

"""INTERPRETACION DEL MODELO : Entre los modelos con que hemos experimentado, hemos elegido el XGBoosClassifier dado que nos ha presentado el mejor valor de AUC training/AUC test. Los puntos de diferencia entre si, se encuentran dentro de lo aceptable 3-5 (AUC train - AUC test : 0.7363 0.6834 = 0.05) .

En el proceso de hiperparametrización, se probaron diferentes parametros y el mejor resultado se logró con un alpha = 0.5, éste parametro soporta la regularización del modelo evitando que sea tan complejo. Hemos optado por un subsampling de 0.8 tras varios intentos. Este parametro es la proporción de submuestra de las instancias de entrenamiento. Establecerlo en 0.5 significa que XGBoost muestrearía aleatoriamente la mitad de los datos de entrenamiento antes de cultivar árboles y esto evitará el sobreajuste. Como este dataset tiene una proporcion muy balanceada de los datos, casi un 50 y 50, decidimos que submuestrar a 0.8 daria mayor variabilidad y evitaria sobreajuste.

Aplicamos alpha = 0.5 (L1) como norma reguladora de coeficientes/variables de menor peso. De acuerdo al df que analizamos, a nuestro criterio, muchas variables sobre la informacion familiar del cliente son irrelevantes para la resolucion del problema, luego lo constantamos al sopesar el peso de las features, de modo que este parametro decidimos usarlo y quedarnos con XGBoostClassifier ya que estaba alineado con nuestro criterio para afrontar este problema, reducir el peso de las variables poco importantes. En otra version del modelo, se probo de combinar alpha con lambda (L2) que se ocupa de minimizar el peso de las variables de gran peso, pero esta combinacion no tuvo buenos resultados.


AUC: 0.66
    'max_depth': [3,6,9],
    'n_estimators': [50, 100, 200],
    'min_child_weight': [1,2,3],
    'subsample' : [0.2]
     n_iter = 12

AUC: 0.6770
    'max_depth': [3,6,9],
    'n_estimators': [100, 200, 400],
    'min_child_weight': [2,3,4],
    'subsample' : [0.8],
    'alpha' : [0.1]

AUC: 0.6749
    'max_depth': [3,6,9],
    'n_estimators': [50, 100, 200],
    'min_child_weight': [1,2,3],
    'subsample' : [0.5]
     n_iter = 13

AUC: 0.6700
    'max_depth': [6,9,12],
    'n_estimators': [50, 100, 200],
    'min_child_weight': [2,3,4],
    'subsample' : [0.8]
     n_iter = 13

AUC: 0.6770
    'max_depth': [3,6,9],
    'n_estimators': [50, 100, 200],
    'min_child_weight': [2,3,4],
    'subsample' : [0.8]
     n_iter = 13

AUC: 0.6770
    'max_depth': [3,6,9],
    'n_estimators': [100, 200, 400],
    'min_child_weight': [1,2,3],
    'subsample' : [0.8]
     n_iter = 13

AUC: 0.6762
    'max_depth': [3,6,9],
    'n_estimators': [100, 200, 400],
    'min_child_weight': [2,3,4],
    'subsample' : [0.8]
     n_iter = 13

AUC: 0.6777
    'max_depth': [6,9,12],
    'n_estimators': [100, 200, 400],
    'min_child_weight': [1,2,3],
    'subsample' : [0.8],
    'lambda' : [0.5]
    'alpha' : [0.3]
     n_iter = 13

AUC: 0.66
    'max_depth': [6,9,12],
    'n_estimators': [50, 100, 200],
    'min_child_weight': [1,2,3],
    'subsample' : [0.5]
     n_iter = 15

AUC: 0.6767
    'max_depth': [3,6,9],
    'n_estimators': [50, 100, 200],
    'min_child_weight': [1,2,3],
    'subsample' : [0.8]
     n_iter = 15

AUC: 0.6700
    'max_depth': [6,9,12],
    'n_estimators': [50, 100, 200],
    'min_child_weight': [2,3,4],
    'subsample' : [0.8]
     n_iter = 15

# TEST

* Evaluación de las métricas de performance en TEST.
"""

y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

y_train_pred_proba = model.predict_proba(X_train)[:, 1]
y_test_pred_proba = model.predict_proba(X_test)[:, 1]

from sklearn.metrics import roc_auc_score

auc_train = roc_auc_score(y_train, y_train_pred_proba)
auc_test = roc_auc_score(y_test, y_test_pred_proba)

print('AUC Train:', round(auc_train,4))
print('AUC Test:', round(auc_test,4))

"""

*   Roc Curve

"""

from sklearn.metrics import roc_curve

# metrics for ROC
fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)
fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred_proba)

#Plot
plt.figure(figsize=[10,8])
plt.plot(fpr_train, tpr_train, label='TRAIN - AUC: {:.4f}'.format(auc_train))
plt.plot(fpr_test, tpr_test, label='TEST - AUC: {:.4f}'.format(auc_test))
plt.title('ROC Curve')
plt.plot([0,0,1],[0,1,1], color='green', linestyle='--', linewidth=0.5, label='Ideal')
plt.plot([0, 1], [0, 1], color='black', linestyle='--', linewidth=0.5, label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc="lower right")
plt.show()

"""*   Al graficar el comportamiento de nuestro modelo entrenado en relación al test para evaluar la tasa de acierto que logra, observamos que la
ROC curve (Receiver Operating Characterictic)  nos enseña un modelo aceptable ya que su valor se encuentra en 0.7363. Un AUC comprendido entre 0.5-1 se considera un buen clasificador.

Del gráfico tambien se desprende que nuestro AUC test no ha caido en problemas de overfitting ya que si bien hay paralelismo con AUC train, no imita exactamente su comportamiento. A mayor área entre las curvas, es decir, cuanto más se acerque AUC test a la diagonal central y se aleje de AUC train, tanto más defectuoso el modelo, ya que clasificaria de manera aleatoria.

Arribamos a la conclusión que nuestro modelo podría considerarse bueno, pero suceptible de nuevos procesamientos que lo pudieran mejorar.

* Confusion Matrix
"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

cm_test = confusion_matrix(y_test, y_test_pred)

ConfusionMatrixDisplay(confusion_matrix=cm_test/len(y_test)).plot(colorbar = False, cmap = 'Blues')
plt.title('Confusion Matrix TEST (%)')
plt.plot()

"""* Accuracy, Precision, Recall y F1-Score"""

cm_test

TN = cm_test[0,0]
TP = cm_test[1,1]
FP = cm_test[0,1]
FN = cm_test[1,0]
total = len(y_test)

accuracy_test = (TN+TP)/total
precision_test = TP/(TP+FP)
recall_test = TP/(TP+FN)
f1_test = 2/(1/recall_test + 1/precision_test)

print('Accuracy:',round(accuracy_test,4))
print('Precision:',round(precision_test,4))
print('Recall:',round(recall_test,4))
print('F1-score:',round(f1_test,4))

"""*   Para ponderar la eficacia del modelo para este proyecto, analizamos las métricas de accuracy, presicion, recall y F1-score.

Accuracy = 0.6309

Es el % de las predicciones positivas que son correctas.

Es una buena métrica si las categorías están equilibradas, nuestra base de datos muestra un balance adecuado entre clientes que se retiran y quienes permanencen.
Esta metrica nos indica los errores generales del AL. En nuestro proyecto predice correctamente en un 63% de los casos, sin embargo, suceptible de mejorarse.

Recall = 0.6605

Recall: % de las clases positivas reales que fueron predecidas correctamente. Nos da información sobre el rendimiento del clasificador puesto que  indica que tan bien nuestro algoritmo puede diferenciar entre verdaderos y falsos positivos

 F1:-score = 0.645

Es una ponderación de la precisión y recall, a diferencia del accuracy no se ve afectada por la distribución de la clase (positivos/negativos). Nos refleja la eficacia de un algoritmo de clasificación.

# INTERPRETABILITY

* Analizamos top features del modelo y su peso en el modelo.
* Plotear SHAP values y el impacto positivo/negativo.
* Comentar las top5 features, su impacto en el target y extraer insights.
* Analisis complementarios:
  * Modelos de arboles: Feature Importances, plot de arbol de decision.
  * Modelos lineales: Coeficentes y formula del modelo.
"""

pip install shap

import shap

#SHAP value: peso en el output final
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)
plt.title('SHAP values')
shap.summary_plot(shap_values, X_test, plot_type="bar", max_display=20)

shap.summary_plot(shap_values, X_test)

eq = sns.displot(x='churn', y='eqpdays', color='pink', rug = True, kind = 'kde' , data= df)
eq.fig.suptitle("Cantidad de dias con el mismo Equipo/ target")
eq.fig.subplots_adjust(top = 0.9)

df["eqpdays"].describe()

"""

*   eqpdays : Number of days (age) of current equipment  

Puede ser que los clientes hagan un cambio de compania cuando se les ofrece la posibilidad de hacer un cambio de dispositivo. Se podria revisar las estrategias de captacion de clientes de otras companias. Un ofrecimiento de financiamiento, o bajos costos de servicio por adquirir un movil nuevo con ellos, podrian ser factores de gran atraccion para realizar un cambio de compania apoyado tambien por dos factores; la facilidad actual de la portabilidad de numero de telefono y la eliminacion de las clausulas de permanencia preestablecida en un servicio de este tipo. Al relacionar graficamente target y eqpdays, observamos que hay una concetracion de clientes que se retiran a los 400 dias aproximadamente con una mayor variabilidad de clientes entre aquello que se retiran-> Churn = 1.

Al tomar la media de la variable eqpdays , obtenemos: 402.419. Esto quiere decir que el tiempo promedio de permanencia con la empresa es de UN año y medio aproximadamente. Por la alta tasa de consumo de dispositivos moviles y la rapidez con que se actualizan los modelos en mercado, podria considerase razonable que un factor imporante en la decision de mantenerse en una compania o retirarse a otra, sea de hecho, la posibilidad de actualizar el disposivito por un modelo mas reciente asociado tambien a las facilidades actuales de hacer este tipo de saltos entre companias.

Se propone investigar las estrategias de captacion de clientes con estos beneficios y analizar asi la posible fuga de clientes ."""

df['avg3mou'].describe()

"""

*  avgmou : Average monthly minutes of use over the life of the client

Esta variable - avgmou- nos refiere al historico de uso de cada cliente en minutos. Es decir, cuanto tiempo en minutos ha usado el servicio desde que incia hasta que termina la relacion contractual. Observamos que la media de uso es de 480 minutos y un valor maximo de 7050 min. Estos valores nos podrian acercar a la idea de la cantidad de  minutos que se podria ofrecer por tarifa. Sin embargo, esta variable nos resulta poco fiable ya que al investigar sobre el uso promedio de un usuario de su telefono movil en intenet, nos encontramos con que en España, el promedio es 183min/mes. De modo que 480 min de media para TODO el ciclo de vida del cliente parece incorrecto.

"""

consumo_neg = df[df['change_mou']<=0].index
len(consumo_neg)

consumo_pos = df[df['change_mou']>=0].index
len(consumo_pos) / len(df['change_mou'])

proporcion_pos = len(consumo_pos) / len(df['change_mou'])
proporcion_pos

"""

*   change_mou : Percentage change in monthly minutes of use.

La variable change_mou refleja el cambio en el consumo mensual medio de minutos, esto quiere decir que si el Porcentaje es 0%, el cliente ha consumido la misma cantidad de minutos promedio que el mes anterior, es decir que ha mantenido su consumo mensual. Un valor negativo indicaria que el cliente uso menos el telefono en el mes actual en relacion al anterior. Y por ultimo un valor de porcentual mayor a cero, nos indica que hubo un incremento en el uso del servicio en minutos. Esta variable podria soportar tambien la variable anterior que refleja la cantidad de minutos usados concretamente.

El 45% de los clientes bajo la variable change_mou ha incremetado el uso de los minutos. Si la lina de razonamiento de la variable anterior se tiene como eje, concluimos que una diferencia positiva en el consumo de minutos, ya sea por valor numerico o porcentual, podrian afectar al abandono del cliente si esto supone un costo adicional o se encuentra limitado en el uso de minutos mensuales por la tarifa que ha contratado. Otra compania podria estar ofrenciendo minutos ilimitados, logrando captar el cliente aun que la oferta del precio del servicio sea la misma.


"""

df.hist('months')

df['months'].describe()

mon = sns.displot(x='churn', y='months', color='pink', rug = True, kind = 'kde' , data= df)
mon.fig.suptitle("Meses totales que el cliente permanecio en la compania/ target")
mon.fig.subplots_adjust(top = 0.9)

df[df['months']>=17]

df[df['months']<=17]

"""

*  months : Total number of months in service.

Months es la variable que describe la cantidad de meses que un cliente permanecio tomando el servicio. De esta grafica podemos observar que la permanencia media con un Churn= 1, es de 17 meses. Esto es correlacinable con la primera feature -avg3mou- que indicaba la cantidad de dias de permanencia. De esta última,  obtuvimos una media de 400 dias, lo cual es coherente con una permanencia de entre 13-17 meses (entre 400 y 500 dias -avg3mou-).

Como la proporcion de permanencia o abandono es muy similar entre los grupos de clientes para esa media de permancia, si asumimos que la bisagra de permanencia en meses se establece en 17, podriamos plantear estratagias de retencion del cliente para aquellos 45k que tienen mayor potencial de retirarse. Evaluar la satisfaccion del cliente y afrecerle alguna actualizacion del servicio o algun beneficio, nos ayudaria a aumentar el numero de clientes que superen una permanencia de 17 meses en la compania.


"""

uniq = sns.displot(x='churn', y='uniqsubs', color='pink', rug = True, kind = 'kde' , data= df)
uniq.fig.suptitle("Numero de personas unicas suscriptas al servicio por hogar/ target")
uniq.fig.subplots_adjust(top = 0.9)

df['uniqsubs'].describe()

"""

*   uniqsubs : numero de personas unicas suscriptas al servicio en un hogar.

Refleja el numero de personas registradas al servicio bajo el mismo nombre de cliente, es decir, si tiene mas lineas asociadas al servicio. Esto es propio de grupos familiares que se adicionan al servicio para disminuir costos por grupo familiar. Esta variable nos indica que en promedio hay una sola persona por servicio contratado. Seria interesante poder extender la permanencia de un usuario al asociarlo con mas lineas posibles a una unica tarifa de manera de simplificar los diferentes servicios de telefonia que una misma unidad familiar posea. Es probable que el ofrecimiento de un paquete compartido para miembros de la familia o integrantes de la unidad habitacional, sea una propuesta interesante para fidelizar clientes. Aun asi esta variable no nos aporta informacion significativa para comprender por que se retirarian del servicio. Podriamos asumir su potencial en caso de saber la norma de la compania en terminos de cuantas personas máximo se pueden añadir a un único plan.

"""

import pickle
pickle.dump(model, open('/content/drive/MyDrive/DSC 0523– Entregable 2 - Borrero, Dottori, He/Modelo/EJERCICIO-ML-Sup/data/traintest.pkl', 'wb'))